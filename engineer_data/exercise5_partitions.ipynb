{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81920f10-5b44-4c07-b797-e59b76afc2a5",
   "metadata": {},
   "source": [
    "# Ejemplo 5 : Particiones de datos con Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7a30d1-1ada-469a-bed3-a6b948df318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/10 07:53:49 WARN Utils: Your hostname, TECNICA, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/09/10 07:53:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/10 07:53:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#Configuración inicial\n",
    "#######################################################\n",
    "from pyspark.sql import SparkSession #Iniciar la sesión de spark\n",
    "\n",
    "# Creamos la sesión de spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EjemploRDD\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "import findspark #Librería para encontrar donde está instalado spark\n",
    "findspark.init() \n",
    "\n",
    "sc = spark.sparkContext  #Crea el contexto de spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad21597-d70d-4ef8-a498-0bea9af04577",
   "metadata": {},
   "source": [
    "### **`parallelize`**\n",
    "\n",
    "**`SparkContext.parallelize(c, numSlices=None)`** Distribuya una colección local de Python para formar un RDD. Se recomienda usar \"range\" si la entrada representa un rango por cuestiones de rendimiento.\n",
    "\n",
    "* **c** : Colección iterable para distribuir\n",
    "* **numSlices** : *int, optional* Número de particiones del nuevo RDD\n",
    "* **Returns** : RDD que representa una colección distribuida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5fea81-d759-417f-a079-0718b2bf2c60",
   "metadata": {},
   "source": [
    "### **`getNumPartitions`**\n",
    "Es un método que obtiene el número de particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b407e6b4-acbb-4475-bafe-602cb2feba7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,1,2,2,3,3,4,5])\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1489847d-b81b-4803-a201-ebd9c5f7e4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,1,2,2,3,3,4,5], 2)\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59b890-39a1-4312-99cf-845b5ad54369",
   "metadata": {},
   "source": [
    "### Modificación de particiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497470b-3774-49a9-87e9-ba3ae35a3017",
   "metadata": {},
   "source": [
    "Podemos modificar la cantidad de particiones, mediante dos transformaciones wide : `coalesce` y `repartition`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec4566-e0ac-46db-904d-c9c17b6d1bba",
   "metadata": {},
   "source": [
    "#### **`coalesce`**\n",
    "\n",
    "**`.coalesce(num_partitions)`**\n",
    "\n",
    "Reduce el número de particiones en un RDD o DataFrame. Optimiza el rendimiento al reducir particiones , especialmente después de operaciones como filter que pueden generar muchas particiones\n",
    "* **num_partitions** : *int* El número de particiones deseadas \n",
    "* **Returns** : DataFrame\n",
    "> **Observaciones** : Esta operación genera una dependencia estrecha; por ejemplo, si se pasa de 1000 particiones a 100, no se realizará una reorganización; en su lugar, cada una de las 100 nuevas particiones reclamará 10 de las particiones actuales. Si se solicita un número mayor de particiones, se mantendrá el número actual. Sin embargo, si se realiza una fusión drástica, por ejemplo, a num_partitions = 1, esto puede resultar en que el cálculo se realice en menos nodos de los deseados (por ejemplo, un nodo en el caso de num_partitions = 1). Para evitar esto, se puede llamar a repartition(). Esto añadirá un paso de reorganización, pero significa que las particiones ascendentes actuales se ejecutarán en paralelo (según el particionamiento actual).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b002406e-96ba-4ecd-9c50-19c24ffeae4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,1,2,2,3,3,4,5], 4)\n",
    "rddlp = rdd.coalesce(3)\n",
    "rddlp.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c1917-bf6a-4fb5-a86d-96c023035214",
   "metadata": {},
   "source": [
    "#### **`repartition`**\n",
    "\n",
    "**`.repartition(num_partitions)`**\n",
    "\n",
    "Cambia el número de particiones , ya sea para aumentarlas o reducirlas. Redistribuye los datos de manera uniforme en un número específico de particiones. Realiza un *shuffle* completo de los datos entre \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1313581-c25c-45bb-8f8e-0ad47e3eba2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
